################################################################################
#
# Copyright (C) Zenoss, Inc. 2005-2020, all rights reserved.
#
################################################################################

HOME_SERVICED=/opt/serviced
HOST_ISVCS_DIR=$HOME_SERVICED/var/isvcs
CONTAINER_ES_DIR=/opt/elasticsearch-serviced
SVC_NAME=/serviced-isvcs_elasticsearch-serviced
NODE_NAME=elasticsearch-serviced
CLUSTER_NAME=$(cat $HOST_ISVCS_DIR/elasticsearch-serviced.clustername)
HOST_ES_DATA_DIR=$HOST_ISVCS_DIR/elasticsearch-serviced/data
CONTAINER_ES_DATA_DIR=$CONTAINER_ES_DIR/data
ELASTIC_BIN=$CONTAINER_ES_DIR/bin/elasticsearch
CONTAINER_ES_LS_DIR=/opt/elasticsearch-logstash
SVC_NAME_LS=/serviced-isvcs_elasticsearch-logstash
NODE_NAME_LS=elasticsearch-logstash
CLUSTER_NAME_LS=$(cat $HOST_ISVCS_DIR/elasticsearch-logstash.clustername)
HOST_ES_LS_DATA_DIR=$HOST_ISVCS_DIR/elasticsearch-logstash/data
CONTAINER_ES_LS_DATA_DIR=$CONTAINER_ES_LS_DIR/data
ELASTIC_LS_BIN=$CONTAINER_ES_LS_DIR/bin/elasticsearch
SERVICED_LOG_DIR=/var/log/serviced
PREUPGRADE_SERVICED_VER_FILE=/tmp/preupgrade-serviced-version.txt

################################################################################
report() {
    local msg
    msg=$1
    shift
    echo ===== "$msg" =====
    echo "$*"
    echo ===================
}

retry() {
    local command
    local duration
    local result
    local timeout
    timeout=$1
    shift
    command="$*"
    duration=0
    until [[ ${duration} -ge ${timeout} ]]; do
        ${command}; result=$?; [ ${result} = 0 ] && break
        duration=$((duration + 1))
        sleep 1
    done
    return ${result}
}

check_elasticsearch() {
    local err
    echo "Waiting 120 seconds for elasticsearch to start ..."
    retry 120 curl http://localhost:9200/_cluster/health &>/dev/null
    err=$?
    return $err
}

migrate_elasticsearch() {
    local err
    echo "Starting export for old elasticsearch storage"
    retry 120 $HOME_SERVICED/bin/elastic -c $HOME_SERVICED/etc/es_cluster.ini \
        -f $HOST_ISVCS_DIR/elasticsearch_data.json -e &>/dev/null
    err=$?
    return $err
}

check_elasticsearch_ls() {
    local err
    echo "Waiting 120 seconds for elasticsearch-logstash to start ..."
    retry 120 curl http://localhost:9100/_cluster/health &>/dev/null
    err=$?
    return $err
}

migrate_elasticsearch_ls() {
    local err
    echo "Starting export for old elasticsearch-logstash storage"
    retry 120 $HOME_SERVICED/bin/elastic -c $HOME_SERVICED/etc/es_cluster.ini \
        -f $HOST_ISVCS_DIR/elasticsearch_logstash_data.json -E &>/dev/null
    err=$?
    return $err
}

version_greater_equal() {
    if [[ "$(printf '%s\n' "$2" "$1" | sort -V | head -n1)" = "$2" ]]; then 
        return 0
    else
        return 1
    fi
}
################################################################################

if [[ "$EUID" -ne 0 ]]; then
  echo "Running this script requires root privileges"
  exit 1
fi

if [[ "$(systemctl is-active serviced)" = "active" ]]; then
    systemctl stop serviced
fi

if [[ ! -d $SERVICED_LOG_DIR ]]; then
    mkdir -p $SERVICED_LOG_DIR
    chgrp root $SERVICED_LOG_DIR
    chmod 1750 $SERVICED_LOG_DIR
fi

#
# CC-3482: preserve the existing access log
#
if [[ -f /var/log/serviced.access.log ]]; then
    echo "Moving /var/log/serviced.access.log to $SERVICED_LOG_DIR/serviced.access.log"
    mv /var/log/serviced.access.log $SERVICED_LOG_DIR
fi

#
# CC-3482: If the current logrotate configuration file uses the old location, then
#      replace it with the new configuration file. Otherwise, the log files might grow
#      without bounds, potentially bringing down the system.
#

if grep /var/log/serviced.access.log /opt/serviced/etc/logrotate.conf 2>/dev/null >/dev/null; then
    echo "Saving /opt/serviced/etc/logrotate.conf as /opt/serviced/etc/logrotate.conf.bak"
    mv /opt/serviced/etc/logrotate.conf /opt/serviced/etc/logrotate.conf.bak

    echo "Replacing /opt/serviced/etc/logrotate.conf with /opt/serviced/etc/logrotate.conf.rpmnew"
    cp /opt/serviced/etc/logrotate.conf.rpmnew /opt/serviced/etc/logrotate.conf

    echo " "
    echo "WARNING: The location of serviced.access.log has moved to /var/log/serviced."
    echo "         /opt/serviced/etc/logrotate.conf has been updated to reflect the new location."
    echo "         Your original settings were saved in /opt/serviced/etc/logrotate.conf.bak"
    echo "         Review both files to see if any settings from /opt/serviced/etc/logrotate.conf.bak"
    echo "         need to be applied to /opt/serviced/etc/logrotate.conf"
    echo "         See the Control Center Release Notes for more information."
fi

#
# NOTE: changing ownership/permissions here has the side-effect of causing
#       "rpm -V serviced" to complain, but we could not get fpm to assign
#       the ownership/permissions at build time.
#
chgrp serviced /etc/default/serviced
chmod 640 /etc/default/serviced

chgrp serviced /opt/serviced
chmod 750 /opt/serviced

#
# if we have a modified cron_zenossdbpack, then keep it in place (preserve customer changes)
#

if [[ -f /etc/cron.d/cron_zenossdbpack.backup ]]; then
    echo "Preserving customer modified cron_zenossdbpack."
    mv /etc/cron.d/cron_zenossdbpack.backup /etc/cron.d/cron_zenossdbpack
fi

touch /etc/cron.d/cron_zenossdbpack

# if preupgrade version of serviced >= 1.9.0 then ES, ES logstash and Zookeeper data
# don't require migration
if [[ -f $PREUPGRADE_SERVICED_VER_FILE ]]; then
    PREUPGRADE_SERVICED_VER=$(cat $PREUPGRADE_SERVICED_VER_FILE)
    echo "Preupgrade serviced version: $PREUPGRADE_SERVICED_VER"
    if version_greater_equal $PREUPGRADE_SERVICED_VER "1.9.0"; then
        echo "ElasticSearch, ElasticSearch logstash and Zookeeper data don't require migration"
        exit 0
    fi
fi

if [[ ! -d $HOST_ES_LS_DATA_DIR || -z $CLUSTER_NAME_LS ]]; then
    echo "Skipping elasticsearch-logstash export on delegate hosts"
else
    echo "Creating a backup of elasticsearch-logstash data in $HOST_ISVCS_DIR"
    cp -ar $HOST_ISVCS_DIR/elasticsearch-logstash $HOST_ISVCS_DIR/elasticsearch-logstash.backup

    echo "Starting docker container elasticsearch-logstash ..."
    docker run --rm -d --name $SVC_NAME_LS -p 9100:9100 \
      -v $HOST_ES_LS_DATA_DIR:$CONTAINER_ES_LS_DATA_DIR zenoss/serviced-isvcs:v68 \
      sh -c "$ELASTIC_LS_BIN -Des.insecure.allow.root=true -Des.node.name=$NODE_NAME_LS -Des.cluster.name=$CLUSTER_NAME_LS"

    if check_elasticsearch_ls; then
		report "SUCCESS" "Container started within timeout"
	else
		report "FAILURE" "Container failed to start within 120 seconds"
	fi

	if migrate_elasticsearch_ls; then
		report "SUCCESS" "Export completed"
	else
		report "FAILURE" "Export failed try make the export manual"
	fi

	echo "Stopping the container with old elasticsearch"
	docker stop $SVC_NAME_LS

    echo "Preparing the host for data import to new elasticsearch storage"
    rm -rf ${HOST_ES_LS_DATA_DIR:?}/*
    groupadd -f elastic -g 1001
    id -u 1001 &>/dev/null || useradd elastic -u 1001 -g 1001
    chown 1001:1001 -R $HOST_ES_LS_DATA_DIR

    echo "Starting container with new elasticsearch logstash"
    docker run --rm -d --name $SVC_NAME_LS -p 9100:9100 \
      -v $HOST_ES_LS_DATA_DIR:$CONTAINER_ES_LS_DATA_DIR zenoss/serviced-isvcs:v69 \
      su elastic -c "$ELASTIC_LS_BIN -Enode.name=$NODE_NAME_LS -Ecluster.name=$CLUSTER_NAME_LS"

    if check_elasticsearch_ls; then
        report "SUCCESS" "Container started within timeout"
    else
        report "FAILURE" "Container failed to start within 120 seconds"
    fi

    echo "Importing data to new elasticsearch logstash"
    $HOME_SERVICED/bin/elastic -i -c $HOME_SERVICED/etc/es_cluster.ini \
      -f $HOST_ISVCS_DIR/elasticsearch_logstash_data.json -I

    echo "Stopping the container with new elasticsearch"
    docker stop $SVC_NAME_LS

fi

# if preupgrade version of serviced >= 1.8.0 then ES and Zookeeper data
# don't require migration
if [[ -f $PREUPGRADE_SERVICED_VER_FILE ]]; then
    PREUPGRADE_SERVICED_VER=$(cat $PREUPGRADE_SERVICED_VER_FILE)
    echo "Preupgrade serviced version: $PREUPGRADE_SERVICED_VER"
    if version_greater_equal $PREUPGRADE_SERVICED_VER "1.8.0"; then
        echo "ElasticSearch and Zookeeper data don't require migration"
        exit 0
    fi
fi

#
# CC-4419: If Elasticsearch configuration file and data folder does not exist
# on the delegate that migration shouldn't start
#
if [[ ! -d $HOST_ES_DATA_DIR || -z $CLUSTER_NAME ]]; then
    echo "Skipping elasticsearch export on delegate hosts"
else
    echo "Creating a backup of elasticsearch-serviced data in $HOST_ISVCS_DIR"
    cp -ar $HOST_ISVCS_DIR/elasticsearch-serviced $HOST_ISVCS_DIR/elasticsearch-serviced.backup

    echo "Starting docker container elasticsearch-serviced ..."
    docker run --rm -d --name $SVC_NAME -p 9200:9200 \
      -v $HOST_ES_DATA_DIR:$CONTAINER_ES_DATA_DIR zenoss/serviced-isvcs:v63 \
      sh -c "$ELASTIC_BIN -f -Des.node.name=$NODE_NAME \
      -Des.cluster.name=$CLUSTER_NAME"

    if check_elasticsearch; then
        report "SUCCESS" "Container started within timeout"
    else
        report "FAILURE" "Container failed to start within 120 seconds"
    fi

    if migrate_elasticsearch; then
        report "SUCCESS" "Export completed"
    else
        report "FAILURE" "Export failed try make the export manual"
    fi

    echo "Stopping the container with old elasticsearch"
    docker stop $SVC_NAME
fi

echo "Copying stub snapshot.0 file to zookeeper storage dir for migration"
echo "from 3.4.x to 3.5.5 version according to the issue ZOOKEEPER-3056"
mv $HOME_SERVICED/isvcs/resources/zookeeper/snapshot.0 \
  $HOST_ISVCS_DIR/zookeeper/data/version-2/

echo "Setting persistent vm.max_map_count in the sysctl.conf"
echo vm.max_map_count=262144 >> /etc/sysctl.conf
sysctl --system
#
# CC-4419: If Elasticsearch configuration file and data folder does not exist
# on the delegate that migration shouldn't start
#
if [[ ! -d $HOST_ES_DATA_DIR || -z $CLUSTER_NAME ]]; then
    echo "Skipping elasticsearch import on delegate hosts"
else

    echo "Preparing the host for data import to new elasticsearch storage"
    rm -rf ${HOST_ES_DATA_DIR:?}/*
    groupadd -f elastic -g 1001
    id -u 1001 &>/dev/null || useradd elastic -u 1001 -g 1001
    chown 1001:1001 -R $HOST_ES_DATA_DIR

    echo "Starting container with new elasticsearch"
    docker run --rm -d --name $SVC_NAME -p 9200:9200 \
      -v $HOST_ES_DATA_DIR:$CONTAINER_ES_DATA_DIR zenoss/serviced-isvcs:v67 \
      su elastic -c "$ELASTIC_BIN -Ecluster.initial_master_nodes=$NODE_NAME \
      -Enode.name=$NODE_NAME -Ecluster.name=$CLUSTER_NAME"


    if check_elasticsearch; then
        report "SUCCESS" "Container started within timeout"
    else
        report "FAILURE" "Container failed to start within 120 seconds"
    fi

    echo "Importing data to new elasticsearch"
    $HOME_SERVICED/bin/elastic -i -c $HOME_SERVICED/etc/es_cluster.ini \
      -f $HOST_ISVCS_DIR/elasticsearch_data.json

    echo "Stopping the container with new elasticsearch"
    docker stop $SVC_NAME

fi

echo "Removing data from old Hbase version"
rm -rf /opt/serviced/var/isvcs/opentsdb/*
